---
title: "小規模チームがゼロからTerraform構成を設計し直した話 - AI時代の運用を見据えて"
emoji: "🏗️"
type: "tech"
topics:
  - "terraform"
  - "gcp"
  - "iac"
  - "ai"
  - "devops"
published: false
publication_name: "pivotmedia"
---

こんにちは。PIVOTでソフトウェアエンジニアとして、Webフロントエンド、バックエンド、インフラを横断的に担当している[@tawachan](https://x.com/tawachan39)です。

この記事では、PIVOTのプロダクトチームでインフラのTerraform化を推進した経験を共有します。IaCできていなかった状態から、AI時代の運用を見据えた構成へと再設計した過程と判断基準について、振り返りながら紹介していきます。

## PIVOTのチーム状況と背景

### チーム体制

PIVOTはビジネス映像メディア「[PIVOT](https://pivotmedia.co.jp/)」を運営する会社です。開発チームは正社員エンジニア3名、QAエンジニア1名、プロダクトマネージャー1名、業務委託で数名という体制で、PIVOTというプロダクトの開発と社内システムのメンテナンスを主なスコープとしています。

エンジニア3名は、iOS、Android、Web（フロントエンド・バックエンド）をそれぞれ担当しており、私がWebを担当しつつインフラ周りも見ています。

### IaCできていなかった過去

もともとIaC化されていない状態でした：

- Google Cloudコンソール上からの手修正が常態化
- インフラ構成がコード化されておらず、属人化
- 変更履歴も追えない状態
- コンソールでぽちぽち操作していると意図しない変更をして事故ることもたまにあり、かなり不健全

よくある話ですが、これではインフラ変更のたびにコンソールを開き、手作業で設定を変更する運用が続きます。属人化も進み、変更履歴も追えません。

### クラウドネイティブ化とIaC再構築の決断

内製化が進む中で、アーキテクチャをクラウドネイティブに寄せる作業が進行していました[^cloudnative]。このタイミングで、改めてIaC化を推進することを決めました。

ゼロからの構築なので、**現在のチーム状況に最適化した構成を新規設計**することにしました。そしてこの機会に、**AI時代の運用も考慮した設計**を取り入れることにしました。

[^cloudnative]: オンプレ時代にはローカルファイルにキャッシュを置くなどStatefulな構成で、そのままGoogle Cloud上のVMに移行していました。サーバーをGoで書き直しながら、ステートレスな構成にしてCloud Runに載せるアーキテクチャ刷新を進めていました。このあたりの話も別途記事にするかもしれません。

## Terraform構成のゼロからの設計

### 設計時に考えた2つの重要な選択

Terraform構成を検討する際、以下の2つの軸で選択を行いました。

#### 選択1: モノレポ vs リポジトリ分散管理

**分散管理での失敗経験**

実は、モノレポ化する前にPoC的に各リポジトリでTerraformを管理してみたことがあります。サーバーやWebフロントエンドのリポジトリそれぞれにCloud RunなどのTerraformコードを配置してみたのですが、早々に問題が見えてきました：

- ほぼ同じリソース（Cloud Run）なのに、リポジトリごとにフォルダ構成が微妙に違う
- 命名規則や変数の定義方法も統一されていない
- どうせ自分が全て操作するのに、リポジトリによって書き方が違うのがやりづらい
- すでに管理が煩雑になりそうで、破綻の予感がした

この経験から、「分散的にやりたくない」という気持ちが強くなり、モノレポ化を真剣に検討し始めました。

**我々の選択: モノレポで一元管理**

理由:

1. **チーム体制**: チームは1つ、インフラを見るのも固定メンバー
2. **実体験からの学び**: 分散管理は小規模チームではすぐに破綻する
3. **AI活用の観点**: コンテキストが一箇所に集約されることで、Claude CodeやCodex CLIが全体を理解しやすい
4. **スケール後の懸念が少ない**: LayerXのようにスケールしているチームでもモノレポを採用している[^layerx]なら、将来的にチームが成長しても大きな問題はないだろう

[^layerx]: [Terraform運用のベストプラクティス - LayerX Tech Blog](https://tech.layerx.co.jp/entry/2025/03/24/113651)

特に2点目と3点目が重要でした。実際に分散管理を試してみて、同じリソース種別が複数箇所に散らばることの煩雑さを体感したことが、モノレポ化の強い動機になりました。また、AIツールは関連するコードが近くにあることで、より適切な提案ができます。

#### 選択2: リソース種別ベースの構成

**PIVOTの状況**

PIVOTは1つのプロダクトを1つのチームで開発しており、複数プロダクトを複数チームで開発しているわけではありません。サーバー、フロントエンド、バッチなど、デプロイ単位や開発担当の違いはありますが、これらは「プロダクト」というより「コンポーネント」の分類に近いものです。

チームトポロジーの観点では、複数のプロダクトチームがそれぞれのインフラを管理する構成が理想的なケースもあります。しかし、我々は1チームで全体を見ているため、そのような組織的な境界はありません。

**我々の選択: リソース種別ベースで横並び管理**

この状況を踏まえ、以下の構成を採用しました：

```
modules/google-cloud/       # リソース種別ごとのモジュール
  ├── cloud-run-api/
  ├── cloud-run-web/
  └── cloud-run-job/

platform/google-cloud/      # 環境ごとの実装
  ├── pivot-stg/
  │   ├── cloud-run/       # 全てのCloud Runサービス
  │   ├── cloud-run-jobs/  # 全てのバッチジョブ
  │   └── ...
  └── pivot-prod/
      └── ...
```

**この構成のメリット:**

1. **横並びでの比較が容易**: 同じリソース種別（例: Cloud Run）の設定が一箇所に集まっているため、設定の統一や比較が簡単
2. **固定担当者の見通しの良さ**: 担当が固定されている場合、リソース種別で整理されている方が認知負荷が低い
3. **AI活用の観点**:
   - 「既存のAPIサーバーと同じメモリ設定で新しいバッチジョブを作って」→ 同じ `cloud-run-jobs/` ディレクトリ内の設定を参照して適切に生成
   - 「全てのCloud Runサービスのタイムアウトを60秒に統一して」→ `cloud-run/` ディレクトリ全体を一度に処理できる
   - 「このAPIサーバーのCloud Monitoringアラートで、エラー率5%以上で通知して」→ `monitoring/` と `cloud-run/` を横断的に参照して設定
   - 変数名や命名規則が統一されているため、AIが既存パターンを学習しやすい

もし複数プロダクトを複数チームで開発する状況になれば、プロダクトチームごとの管理を検討することになるでしょう。しかし現時点では、リソース種別ベースで横並び管理することが、最も見通しがよく効率的だと判断しました。

## 採用した構成の詳細

### 状態管理の設計

**tfstateはリソース種別ごとに分割**し、GCS bucketで管理しています。

```hcl
# platform/pivot-prod/cloud-run/backend.tf
terraform {
  backend "gcs" {
    bucket = "pivot-terraform-state"
    prefix = "prod/cloud-run"
  }
}
```

なぜ分割するのか:

- **Blast Radiusの最小化**: 誤った変更の影響範囲を限定
- **並行作業の容易性**: 異なるリソース種別なら同時に作業できる
- **変更頻度の違い**: 頻繁に変更するリソースと滅多に触らないリソースを分離

### GitOpsフローの実現

**GitHub Actions + OIDC連携**でCI/CDを構築しています。

#### 基本的な仕組み

- **PR時**: 変更されたTerraformコードに対して自動でplanを実行し、結果をPRコメントに投稿
- **マージ時**: mainブランチへのマージで自動apply
- **認証**: Workload Identity連携により、シークレットキー不要で安全に認証
- **権限分離**: planとapplyで異なるサービスアカウントを使用

#### 複数のtfstateへの対応

tfstateをリソース種別ごとに分割しているため、変更されたディレクトリを検出し、該当するstackに対してのみplan/applyを実行する仕組みを構築しています。これにより、Cloud Runの変更時にはCloud Runのstackのみが処理され、他のリソースには影響しません。

また、`modules/` 配下が変更された場合は、そのmoduleを利用している全てのstackに対してplanを実行します。これにより、共通モジュールの変更による影響範囲を事前に確認できます。

この仕組みの詳細については、別途記事にする予定です。

#### Plan結果の可視化

Terraform plan結果がPRコメントに自動投稿され、変更内容が可視化されます。レビュアーも影響範囲を確認しやすくなります。

mainブランチへのマージで自動applyが実行され、完了すると元のPRコメントに結果が追記されます。plan結果とapply結果が同じコメント内に並ぶため、変更の意図と実際の適用結果を一箇所で確認できます。

![PRコメントでのTerraform Plan/Apply結果](/images/terraform-plan-apply-pr-comment.png)

**誰でも安全にインフラ変更できる環境**

この仕組みにより、エンジニアなら誰でも以下のフローでインフラ変更ができます：

1. ブランチを切ってTerraformコードを変更
2. PRを作成すると、自動でplan結果がコメントされる
3. レビュアーが影響範囲を確認
4. マージすると自動で本番環境に適用

Google Cloudコンソールを直接触る必要はありません（むしろ禁止しています）。

## AI時代を見据えた運用実例

この構成がどうAI活用に有利なのか、具体例を示します。

### Claude Code / Codex CLIでの実際の操作例

#### 1. Cronスケジュール更新

```
「毎朝のレポート生成バッチを9時から10時に変更して」
```

→ `platform/pivot-prod/cloud-run-jobs/` 内の該当リソースを特定し、cron式を更新

全体のコンテキストから適切なリソースを即座に判断できます。リソースが点在していると、AIは「どのリポジトリのどのファイルか」を探すところから始める必要があります。

#### 2. Cloud Run設定変更

```
「APIサーバーのメモリを2GBに増やして、CPUも2コアに」
```

→ `platform/pivot-prod/cloud-run/` 内の他サービスの設定例を参考に適切な構文で変更

同じディレクトリ内に類似の設定が並んでいるため、AIは既存の書き方を踏襲した変更を提案できます。

#### 3. 新規リソース追加

```
「既存のバッチサーバーと同じ構成で、新しいデータ処理用のCloud Run Jobを作って」
```

→ 既存リソースをテンプレートとして参照し、命名規則や設定値を踏襲した新規リソース定義を生成

この「既存リソースを参考にして新規作成」というパターンは、リソースベース構成だと特に強力です。

#### 4. モニタリング条件変更

```
「エラー率のアラート閾値を5%から3%に下げて」
```

→ `platform/pivot-prod/monitoring/` 配下の他アラート設定と一貫性を保った変更

（注: 現在monitoringディレクトリはまだ作成していないが、今後追加予定）

### なぜこの構成がAI活用に有利なのか

1. **統合的なコンテキスト**
   - 全リソースが1箇所にあるため、AIが全体を把握しやすい
   - 「このサービス」と曖昧に言っても、コンテキストから特定可能

2. **参照可能な類似例**
   - 同じリソース種別が横並びで存在
   - AIが既存設定をテンプレートとして活用
   - 一貫性のある提案が得られる

3. **自然言語からの変更が容易**
   - 技術的な詳細を覚えていなくても変更できる
   - 「〜と同じように」が通じる
   - インフラに不慣れなメンバーも変更しやすい

従来は「Terraformの書き方」を覚える必要がありましたが、AI時代では「何をしたいか」を自然言語で伝えれば、AIが適切なTerraformコードに変換してくれます。この時、参考にできるコードが近くにあることが重要になります。

## LayerX記事からの学びと我々の解釈

Terraform構成を検討する中で、前述のLayerXの記事に出会いました。

### 参考にした観点

**1. 中央管理の合理性**

LayerXは、メンバーが多く、プロダクト側にインフラ責務を渡してもよさそうな規模でも、メンテコスト観点で中央管理を選択していました。

**我々の解釈**: 大規模チームでさえ中央管理なら、小規模チームの我々はより一層、集約管理が合理的です。

**2. 将来の拡張を見越した設計**

GitHub組織管理、マルチクラウド等も視野に入れたディレクトリ構成を参考にしました。

我々も同様のアプローチで、将来的に以下を追加予定：

- `modules/github/`: GitHub組織・チーム・リポジトリ管理
- `modules/aws/`: AWS リソース（将来的に使う可能性）
- `modules/datadog/`: Datadog設定（現在検討中）

新規リソースが自然とTerraform化される流れを作ることが重要だと感じました。

**3. 温度感の把握**

細かいTipsまでは参考にできていませんが、全体的なアプローチや考え方の方向性を確認できました。特に「プロダクトチームへの責務移譲よりも、中央管理のメリット」という判断軸は、自チームの状況に合わせて解釈・最適化する上で参考になりました。

## この意思決定のポイント

### 技術的正解はない、状況依存の選択

Terraform構成に「絶対的な正解」は存在しない。以下の要素で最適解は変わる：

- チーム規模
- 成長フェーズ
- インフラ担当の体制
- プロダクトの独立性

### 我々の判断軸（2024-2025年時点）

1. **小規模チームのフットワークの軽さを活かす**
   - 固定メンバーで見通しよく管理
   - 素早い意思決定と変更

2. **AI時代のコード構成への配慮**
   - コンテキスト集約によるAI活用の最大化
   - 自然言語でのインフラ操作を前提とした設計

3. **将来の拡張性**
   - GitHub管理のIaC化
   - 他サービス・他クラウドの追加も見据えた箱作り

### 将来の再検討ポイント

この構成がフィットしなくなるタイミング：

- プロダクトチームが複数に増え、独立性が高まった時
- インフラ担当が複数になり、責任範囲を分けたい時
- プロダクトごとのデプロイサイクルが完全に独立した時

その時は改めて、プロダクトベース構成も検討すればよいと考えています。重要なのは「今のチームに最適化する」ことと「状況が変われば構成も変える柔軟性を持つ」ことです。

## 現在の到達点と今後

### 実現できたこと

- プロダクト開発に関わる主要リソースのTerraform化完了
- GitOpsフローの確立（PR→plan、merge→apply）
- 誰でも安全にインフラ変更できる環境
- AI活用を前提とした構成設計

### 今後の課題

- ネットワーク周りなど基盤的なリソースのTerraform化
- より細かいmodule化による再利用性向上
- チームスケール時の構成見直し検討
- GitHub組織管理のIaC化

### PIVOTでのIaC文化

現在、以下のような運用が定着しています：

- Google Cloudコンソール直接変更は原則禁止
- インフラ変更もコードレビュー文化
- エンジニア誰でもインフラに触れる環境
- **AI支援によるインフラ操作の民主化**

特に最後の点は重要です。Terraformの書き方を知らないメンバーでも、AIに自然言語で指示することで、インフラ変更を提案できるようになりました。

## おわりに

振り返ると、Terraform構成の再設計は、技術的な挑戦であると同時に、チームの状況を深く理解する機会でもありました。

今回の取り組みを通じて学んだことは、「Terraform構成に絶対的な正解はない」ということです。ベストプラクティスは参考にしつつも、自分たちのチームの状況、成長フェーズ、文化に合わせて選択することが重要です。そして、状況が変われば構成も変える柔軟性を持つことが大切だと感じています。

特に印象的だったのは、**AI活用を前提にした設計の重要性**です。これからのインフラ運用では、AIがコードを読み書きすることが前提になります。コンテキストの集約、参照可能性、一貫性といった要素が、従来以上に重要になってきています。

また、歴史的経緯を引きずるより、今に最適化した構成を新規設計する勇気も必要でした。内製化やアーキテクチャ刷新のタイミングは、そのための絶好のチャンスです。PIVOTでは主要リソースのIaC化を達成し、誰でも安全にインフラ変更できる環境を実現できました。

この記事が、同じような状況にあるチームの参考になれば幸いです。もし質問やフィードバックがあれば、ぜひコメントやXでお気軽に声をかけてください。
